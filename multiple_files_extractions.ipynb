{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea52add6-80b7-4b40-9624-b65f28207120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b70b19-3f5a-4aec-9ecf-0bc9e35901f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to log ETL events\n",
    "log_file = \"log_file.txt\"\n",
    "\n",
    "# Final output file\n",
    "target_file = \"transformed_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552c3f6-375b-440e-ae6b-0d0324e05dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log any message with timestamp into the log file\n",
    "def log_progress(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S'  # Format: Year-Monthname-Day-Hour-Minute-Second\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{timestamp},{message}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4293c20-a16c-4f20-837e-e276dbe3f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check XML file headers function\n",
    "def get_xml_headers(file_to_process):\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Grab first row for header preview\n",
    "    first_row = root[0]\n",
    "    headers = [elem.tag for elem in first_row]\n",
    "    \n",
    "    print(\"XML Headers Found:\", headers)\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cb03c-bcfc-4700-8836-84b9c27b5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace your_file,xml with your file\n",
    "get_xml_headers(\"your_file.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf09e7-f9ee-4eeb-9df8-37a39b4017db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction function for CSV files\n",
    "def extract_from_csv(file_to_process):\n",
    "    # Directly read CSV into DataFrame\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe\n",
    "\n",
    "# Extraction function for JSON files\n",
    "def extract_from_json(file_to_process):\n",
    "    # Read JSON (line-delimited) into DataFrame\n",
    "    dataframe = pd.read_json(file_to_process, lines=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbd704-b721-422f-b8e5-3295af338845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extraction function for XML files with dynamic parsing\n",
    "def extract_from_xml(file_to_process):\n",
    "    # Define expected schema and datatypes (customize this to match your needs)\n",
    "    dtype_map = {\n",
    "        \"car_model\": str,\n",
    "        \"year_of_manufacture\": int,\n",
    "        \"price\": float,\n",
    "        \"fuel\": str\n",
    "    }\n",
    "\n",
    "    # Initialize empty DataFrame with correct types\n",
    "    dataframe = pd.DataFrame({col: pd.Series(dtype=dtype) for col, dtype in dtype_map.items()})\n",
    "\n",
    "    # Parse XML file\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Iterate over each entry in the XML\n",
    "    for row in root:\n",
    "        record = {}\n",
    "        for key in dtype_map:\n",
    "            element = row.find(key)\n",
    "            if element is not None and element.text is not None:\n",
    "                try:\n",
    "                    record[key] = dtype_map[key](element.text.strip())\n",
    "                except ValueError:\n",
    "                    record[key] = None  # Handle type conversion errors\n",
    "            else:\n",
    "                record[key] = None  # Handle missing fields\n",
    "        dataframe = pd.concat([dataframe, pd.DataFrame([record])], ignore_index=True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d90d97-4b63-4655-b5ca-c449602a65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General extraction function for all supported file types\n",
    "def extract():\n",
    "    # Create an empty DataFrame with predefined columns\n",
    "    extracted_data = pd.DataFrame(columns=['car_model', 'year_of_manufacture', 'price', 'fuel'])\n",
    "\n",
    "    # Extract from all CSV files in the directory, excluding the output target file\n",
    "    for csvfile in glob.glob(\"*.csv\"):\n",
    "        if csvfile != target_file:\n",
    "            extracted_data = pd.concat([extracted_data, extract_from_csv(csvfile)], ignore_index=True)\n",
    "\n",
    "    # Extract from all JSON files\n",
    "    for jsonfile in glob.glob(\"*.json\"):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_json(jsonfile)], ignore_index=True)\n",
    "\n",
    "    # Extract from all XML files\n",
    "    for xmlfile in glob.glob(\"*.xml\"):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_xml(xmlfile)], ignore_index=True)\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9591e792-79d5-4ff3-98f7-95c4db42aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform function to clean and normalize the data\n",
    "def transform(data):\n",
    "    # Round price to 2 decimal places\n",
    "    if 'price' in data.columns:\n",
    "        data['price'] = pd.to_numeric(data['price'], errors='coerce').round(2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9d98a-9b2f-4798-86ee-7fb70e75e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final transformed data into a CSV\n",
    "def load_data(target_file, transformed_data):\n",
    "    transformed_data.to_csv(target_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5b809a-dd7a-41c4-bb25-c8bdbd8825eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- ETL Pipeline Execution Starts Below ---------\n",
    "\n",
    "log_progress(\"ETL Job Started\")\n",
    "\n",
    "log_progress(\"Extract phase Started\")\n",
    "extracted_data = extract()\n",
    "log_progress(\"Extract phase Ended\")\n",
    "\n",
    "log_progress(\"Transform phase Started\")\n",
    "transformed_data = transform(extracted_data)\n",
    "print(\"Transformed Data\")\n",
    "print(transformed_data)\n",
    "log_progress(\"Transform phase Ended\")\n",
    "\n",
    "log_progress(\"Load phase Started\")\n",
    "load_data(target_file, transformed_data)\n",
    "log_progress(\"Load phase Ended\")\n",
    "\n",
    "log_progress(\"ETL Job Ended\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c98fd-3b64-4138-ab27-77067710b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview what the extracted data looks like\n",
    "extracted_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
